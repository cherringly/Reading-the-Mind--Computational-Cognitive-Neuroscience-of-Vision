{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "69c13e48",
      "metadata": {
        "id": "69c13e48"
      },
      "source": [
        "# Assignment 1: Representation, space and embedding (10 pts in total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4306759a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4306759a",
        "outputId": "3dce3f62-01b8-4ddb-bd1f-707585aad4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "# Install the gensim library\n",
        "!pip install gensim\n",
        "\n",
        "# Import packages\n",
        "import gensim.downloader\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3a1338d",
      "metadata": {
        "id": "f3a1338d"
      },
      "source": [
        "You will load a small pre-trained word-embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fb101cd4",
      "metadata": {
        "id": "fb101cd4"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained GloVe model\n",
        "model = gensim.downloader.load('glove-wiki-gigaword-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "15b72b01",
      "metadata": {
        "id": "15b72b01"
      },
      "outputs": [],
      "source": [
        "# Get the embedding vector for the word \"woman\"\n",
        "woman_vector = model['woman']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee1729b8",
      "metadata": {
        "id": "ee1729b8"
      },
      "source": [
        "#### ✏️ Do it yourself (1 pt):\n",
        "Get the dimension of this embedding space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "aa3dbc83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa3dbc83",
        "outputId": "d73dc896-e8a1-4396-ffac-8cc58027c0a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dimension of the embedding space is 50.\n"
          ]
        }
      ],
      "source": [
        "# Insert your code here\n",
        "embedding_dim = len(woman_vector)\n",
        "print(f\"The dimension of the embedding space is {embedding_dim}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96bbd978",
      "metadata": {
        "id": "96bbd978"
      },
      "source": [
        "#### ✏️ Do it yourself (1 pt):\n",
        "Get embeddings for the words “queen”, “uncle” and “tree.”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7a2e3ff3",
      "metadata": {
        "id": "7a2e3ff3"
      },
      "outputs": [],
      "source": [
        "# Insert your code here\n",
        "queen_vector = model['queen']\n",
        "uncle_vector = model['uncle']\n",
        "tree_vector = model['tree']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42a48d4b",
      "metadata": {
        "id": "42a48d4b"
      },
      "source": [
        "#### ✏️ Do it yourself (2 pts):\n",
        "Compute the Euclidean distance between the embeddings of the following word pairs: (1) \"woman\" and \"queen\", (2) \"woman\" and \"uncle\", and (3) \"woman\" and \"tree\". \\\n",
        "_Hint: use `np.linalg.norm` to compute L2 norm_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5b0d2445",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b0d2445",
        "outputId": "c641b965-2c41-40de-bde5-347a6c89cce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The distance between woman and queen is: 4.825778961181641\n",
            "The distance between woman and uncle is: 4.893293857574463\n",
            "The distance between woman and tree is: 6.05571174621582\n"
          ]
        }
      ],
      "source": [
        "# Insert your code here\n",
        "def euclidean_distance(v1,v2):\n",
        "  return np.linalg.norm(v1-v2)\n",
        "\n",
        "ed_woman_queen = euclidean_distance(woman_vector, queen_vector)\n",
        "ed_woman_uncle = euclidean_distance(woman_vector, uncle_vector)\n",
        "ed_woman_tree = euclidean_distance(woman_vector, tree_vector)\n",
        "\n",
        "print(f\"The euclidean distance between woman and queen is: {ed_woman_queen}\")\n",
        "print(f\"The euclidean distance between woman and uncle is: {ed_woman_uncle}\")\n",
        "print(f\"The euclidean distance between woman and tree is: {ed_woman_tree}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4006221",
      "metadata": {
        "id": "c4006221"
      },
      "source": [
        "#### ✏️ Do it yourself (2 pts):\n",
        "Compute the cosine distance between the embeddings of the following word pairs: (1) \"woman\" and \"queen\", (2) \"woman\" and \"uncle\", and (3) \"woman\" and \"tree\". \\\n",
        "_Hint: use `@` to compute dot product_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "14e770ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14e770ac",
        "outputId": "59b266f9-b929-41b9-ec78-e680d01833f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cosine distance between woman and queen is: 0.3996894359588623\n",
            "The cosine distance between woman and uncle is: 0.4503743648529053\n",
            "The cosine distance between woman and tree is: 0.6251512169837952\n"
          ]
        }
      ],
      "source": [
        "# Insert your code here\n",
        "def cos_distance(v1,v2):\n",
        "  dot_product = v1@v2\n",
        "  norm_product = np.linalg.norm(v1)*np.linalg.norm(v2)\n",
        "  return 1-(dot_product/norm_product)\n",
        "\n",
        "cd_woman_queen = cos_distance(woman_vector, queen_vector)\n",
        "cd_woman_uncle = cos_distance(woman_vector, uncle_vector)\n",
        "cd_woman_tree = cos_distance(woman_vector, tree_vector)\n",
        "\n",
        "print(f\"The cosine distance between woman and queen is: {cd_woman_queen}\")\n",
        "print(f\"The cosine distance between woman and uncle is: {cd_woman_uncle}\")\n",
        "print(f\"The cosine distance between woman and tree is: {cd_woman_tree}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57febd83",
      "metadata": {
        "id": "57febd83"
      },
      "source": [
        "#### ✏️ Do it yourself (1 pt):\n",
        "Compute the cosine similarity between the embeddings of the following word pairs: (1) \"woman\" and \"queen\", (2) \"woman\" and \"uncle\", and (3) \"woman\" and \"tree\". \\\n",
        "_Hint: compute consine similarity from consine distance_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "080027e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "080027e8",
        "outputId": "0d99473c-ae23-4f12-9a80-d118b7d0d23e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cosine similarity between woman and queen is: 0.6003105640411377\n",
            "The cosine similarity between woman and uncle is: 0.5496256351470947\n",
            "The cosine similarity between woman and tree is: 0.37484878301620483\n"
          ]
        }
      ],
      "source": [
        "# Insert your code here\n",
        "def cos_similarity(v1,v2):\n",
        "  return 1-cos_distance(v1,v2)\n",
        "\n",
        "cs_woman_queen = cos_similarity(woman_vector, queen_vector)\n",
        "cs_woman_uncle = cos_similarity(woman_vector, uncle_vector)\n",
        "cs_woman_tree = cos_similarity(woman_vector, tree_vector)\n",
        "\n",
        "print(f\"The cosine similarity between woman and queen is: {cs_woman_queen}\")\n",
        "print(f\"The cosine similarity between woman and uncle is: {cs_woman_uncle}\")\n",
        "print(f\"The cosine similarity between woman and tree is: {cs_woman_tree}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0c1f082",
      "metadata": {
        "id": "e0c1f082"
      },
      "source": [
        "#### ✏️ Do it yourself (1 pts):\n",
        "Combining the above embedding examples, explain why cosine distance is generally preferred over Euclidean distance when comparing embeddings.\n",
        "\n",
        "Write your answer here:\n",
        "> **Answer:**\n",
        ">\n",
        "> Cosine distance is generally preferred over Euclidean distance because it focuses on the angle between the two vectors, not their magnitudes. When many dimensions are involved, Euclidean distances become less meaningful, but cosine distances don't depend on the absolute value / magnitudes. Also, cosine distances are bounded between -1 and 1, wherease Euclidean distances can vary a lot depending on embedded dimensions.\n",
        ">   \n",
        ">   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82294b06",
      "metadata": {
        "id": "82294b06"
      },
      "source": [
        "### Get embedding of an image from a vision model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dfeac77",
      "metadata": {
        "id": "9dfeac77"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "725c2bc8",
      "metadata": {
        "id": "725c2bc8"
      },
      "outputs": [],
      "source": [
        "# Download the image file\n",
        "!wget -O surfing.png \"https://drive.google.com/uc?export=download&id=1drpMOkT81nX2GwlvOvjRvs1-YwKlEIQs\" -q\n",
        "\n",
        "# Display the image\n",
        "img = Image.open(\"surfing.png\")\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252ec3b4",
      "metadata": {
        "id": "252ec3b4"
      },
      "source": [
        "Load in the AlexNet model.\n",
        "Visualize the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d8be4d6",
      "metadata": {
        "id": "3d8be4d6"
      },
      "outputs": [],
      "source": [
        "# Depending on the version of torchvision, you might need to use:\n",
        "# model = models.alexnet(pretrained=True) # for torchvision versions < 0.13\n",
        "model = models.alexnet(weights='IMAGENET1K_V1') # for torchvision versions >= 0.13\n",
        "\n",
        "# Make the model in evaluation mode, so it does not update weights\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b495161",
      "metadata": {
        "id": "3b495161"
      },
      "source": [
        "### Demo on how to get activations (i.e., embeddings) from a specific layer of the model\n",
        "1. Read in the image\n",
        "2. Preprocess the image to fit the input size of the model\n",
        "3. Define the hook function (a callback function) and attach it to a specific layer\n",
        "4. Forward-pass the image to obtain activations (embeddings) from the specified layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ac13f1",
      "metadata": {
        "id": "71ac13f1"
      },
      "outputs": [],
      "source": [
        "# Set device for computation\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Open the image file\n",
        "input_img = Image.open(\"surfing.png\")\n",
        "\n",
        "# Preprocess the image to fit the input size of the model\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Apply the preprocessing to the input image\n",
        "input_tensor = preprocess(input_img)\n",
        "\n",
        "# Add a batch dimension so the model can process the image\n",
        "x = input_tensor.unsqueeze(0).to(device)  # (1, 3, 224, 224)\n",
        "\n",
        "\n",
        "# Define a dictionary to store the activations\n",
        "activations = {}\n",
        "\n",
        "# Define the hook function. This function will be called during the forward pass.\n",
        "def hook_fn(name):\n",
        "    def _hook(module, input, output):\n",
        "        activations[name] = output.detach()\n",
        "    return _hook\n",
        "\n",
        "# Register the hook on the fc7 layer\n",
        "handle = model.classifier[4].register_forward_hook(hook_fn(\"fc7\"))\n",
        "\n",
        "# Run the model with the input image to trigger the hook\n",
        "with torch.no_grad():\n",
        "    _ = model(x)\n",
        "\n",
        "# Remove the hook in case you want to register another one later\n",
        "handle.remove()\n",
        "\n",
        "# Get the embedding from the fc7 layer\n",
        "emb = activations[\"fc7\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09095595",
      "metadata": {
        "id": "09095595"
      },
      "source": [
        "Next, you will download two other images and get their embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4bee857",
      "metadata": {
        "id": "f4bee857"
      },
      "outputs": [],
      "source": [
        "# Download two other image files\n",
        "!wget -O img01.png \"https://drive.google.com/uc?export=download&id=1Y5nIJ_0VOHTWWx2LMpE-oiJuwXoWjU-N\" -q\n",
        "!wget -O img02.png \"https://drive.google.com/uc?export=download&id=1zvHbYiO-6N4kma-KLi0XBYSwE2niadjQ\" -q\n",
        "\n",
        "# Display the first image\n",
        "display(Image.open(\"img01.png\"))\n",
        "\n",
        "# Display the second image\n",
        "display(Image.open(\"img02.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ec75710",
      "metadata": {
        "id": "6ec75710"
      },
      "source": [
        "#### ✏️ Do it yourself (2 pts):\n",
        "Get the embeddings of 'img01' and 'img02' from the _fc7_ layer of Alexnet (1 pt) and compute the cosine distance between the embeddings of image pairs: (1) \"surfing\" and \"img01\", (2) \"surfing\" and \"img02\" (1 pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3682825",
      "metadata": {
        "id": "b3682825"
      },
      "outputs": [],
      "source": [
        "# Insert your code here"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}